{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   1   2   3   4   5   6   7     8     9   ...   82   83   84   85  \\\n",
      "0      1800   2   1   1   3   1   6   3  56.0   9.0  ...   93   68   78   68   \n",
      "1      1800   2   1   1   3   1   7   3  56.0   7.3  ...   77   83   95   83   \n",
      "2      1700   4   1   1   4   1   1   3  56.0   5.6  ...   91   65   91   65   \n",
      "3      1700   4   1   1   4   1   3   3  54.0   6.5  ...   76   43   76   43   \n",
      "4      1700   4   1   1   4   1   8   3  53.0  10.9  ...  115   61  115   61   \n",
      "...     ...  ..  ..  ..  ..  ..  ..  ..   ...   ...  ...  ...  ...  ...  ...   \n",
      "84338  1700   4   1   1   3   3   8   3  56.0   7.5  ...   87  121   87  121   \n",
      "84339  1200  10   2   1   3   1   1   5  55.0  22.1  ...   64   48   38   48   \n",
      "84340  1200  10   2   1   3   1   2   3  52.0  14.3  ...   84   72   52   72   \n",
      "84341  1200  10   2   1   3   1   7   4  55.0   4.2  ...   92   97   71   97   \n",
      "84342  1200  10   2   1   3   1   8   4  55.0   9.1  ...   67   62   87   62   \n",
      "\n",
      "        86   87   88   89   90   91  \n",
      "0       78   68   50   68   99   68  \n",
      "1       95   83   68   83   91   83  \n",
      "2       91   65   91   65   78   65  \n",
      "3       48   43   48   43   78   43  \n",
      "4       67   61   67   61   87   61  \n",
      "...    ...  ...  ...  ...  ...  ...  \n",
      "84338  116  121  116  121  116  121  \n",
      "84339   68   48   78   48   77   48  \n",
      "84340   37   72   85   72  112   72  \n",
      "84341   71   97   92   97   83   97  \n",
      "84342   65   76  115   76  209   76  \n",
      "\n",
      "[84343 rows x 92 columns]\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_104 (Dense)            (None, 53)                4929      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 53)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 33)                1782      \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 4)                 136       \n",
      "=================================================================\n",
      "Total params: 6,847\n",
      "Trainable params: 6,847\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 59040 samples, validate on 25303 samples\n",
      "Epoch 1/12\n",
      "59040/59040 [==============================] - 1s 19us/step - loss: 1.3960 - accuracy: 0.2889 - val_loss: 1.3601 - val_accuracy: 0.3108\n",
      "Epoch 2/12\n",
      "59040/59040 [==============================] - 1s 16us/step - loss: 1.3585 - accuracy: 0.3136 - val_loss: 1.3535 - val_accuracy: 0.3232\n",
      "Epoch 3/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3528 - accuracy: 0.3236 - val_loss: 1.3511 - val_accuracy: 0.3242\n",
      "Epoch 4/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3494 - accuracy: 0.3292 - val_loss: 1.3489 - val_accuracy: 0.3252\n",
      "Epoch 5/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3465 - accuracy: 0.3324 - val_loss: 1.3501 - val_accuracy: 0.3266\n",
      "Epoch 6/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3452 - accuracy: 0.3340 - val_loss: 1.3492 - val_accuracy: 0.3264\n",
      "Epoch 7/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3449 - accuracy: 0.3338 - val_loss: 1.3499 - val_accuracy: 0.3303\n",
      "Epoch 8/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3431 - accuracy: 0.3351 - val_loss: 1.3486 - val_accuracy: 0.3251\n",
      "Epoch 9/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3414 - accuracy: 0.3363 - val_loss: 1.3490 - val_accuracy: 0.3286\n",
      "Epoch 10/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3413 - accuracy: 0.3376 - val_loss: 1.3484 - val_accuracy: 0.3277\n",
      "Epoch 11/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3395 - accuracy: 0.3386 - val_loss: 1.3491 - val_accuracy: 0.3298\n",
      "Epoch 12/12\n",
      "59040/59040 [==============================] - 1s 15us/step - loss: 1.3385 - accuracy: 0.3404 - val_loss: 1.3488 - val_accuracy: 0.3285\n",
      "Test loss: 1.3488017125680543\n",
      "Test accuracy: 0.32849860191345215\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "batch_size = 128\n",
    "win_classes = 4\n",
    "epochs = 12\n",
    "\n",
    "# the data, split between train and test sets\n",
    "x = pd.read_csv(\"input.csv\", header=None)\n",
    "print(x)\n",
    "x = preprocessing.scale(x)\n",
    "y = pd.read_csv(\"answer.csv\", header=None)\n",
    "y = keras.utils.to_categorical(y, win_classes)\n",
    "\n",
    "# トレーニング用とテスト用を分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "(x_train, x_test,\n",
    " y_train, y_test) = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=0,\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "model.add(Dense(53, activation='relu', input_shape=(92,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(33, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(win_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save('model.h5', include_optimizer=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
