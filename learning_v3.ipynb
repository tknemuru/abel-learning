{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91142 samples, validate on 39061 samples\n",
      "Epoch 1/100\n",
      "91142/91142 [==============================] - 3s 28us/step - loss: 0.8274 - val_loss: 0.7689\n",
      "Epoch 2/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.8042 - val_loss: 0.7299\n",
      "Epoch 3/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7778 - val_loss: 0.7234\n",
      "Epoch 4/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7672 - val_loss: 0.7106\n",
      "Epoch 5/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7591 - val_loss: 0.7025\n",
      "Epoch 6/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7542 - val_loss: 0.7105\n",
      "Epoch 7/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.7467 - val_loss: 0.6952\n",
      "Epoch 8/100\n",
      "91142/91142 [==============================] - 3s 29us/step - loss: 0.7436 - val_loss: 0.6907\n",
      "Epoch 9/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7415 - val_loss: 0.6859\n",
      "Epoch 10/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7360 - val_loss: 0.6870\n",
      "Epoch 11/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.7303 - val_loss: 0.6808\n",
      "Epoch 12/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7303 - val_loss: 0.6751\n",
      "Epoch 13/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7293 - val_loss: 0.6822\n",
      "Epoch 14/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7248 - val_loss: 0.6739\n",
      "Epoch 15/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.7218 - val_loss: 0.6814\n",
      "Epoch 16/100\n",
      "91142/91142 [==============================] - 2s 26us/step - loss: 0.7219 - val_loss: 0.6702\n",
      "Epoch 17/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7175 - val_loss: 0.6834\n",
      "Epoch 18/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7202 - val_loss: 0.6688\n",
      "Epoch 19/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7153 - val_loss: 0.6654\n",
      "Epoch 20/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7138 - val_loss: 0.6609\n",
      "Epoch 21/100\n",
      "91142/91142 [==============================] - 2s 26us/step - loss: 0.7153 - val_loss: 0.6631\n",
      "Epoch 22/100\n",
      "91142/91142 [==============================] - 2s 26us/step - loss: 0.7136 - val_loss: 0.6642\n",
      "Epoch 23/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7112 - val_loss: 0.6600\n",
      "Epoch 24/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7102 - val_loss: 0.6710\n",
      "Epoch 25/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7080 - val_loss: 0.6711\n",
      "Epoch 26/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.7082 - val_loss: 0.6598\n",
      "Epoch 27/100\n",
      "91142/91142 [==============================] - 3s 28us/step - loss: 0.7070 - val_loss: 0.6633\n",
      "Epoch 28/100\n",
      "91142/91142 [==============================] - 2s 26us/step - loss: 0.7041 - val_loss: 0.6559\n",
      "Epoch 29/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7039 - val_loss: 0.6575\n",
      "Epoch 30/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.7052 - val_loss: 0.6626\n",
      "Epoch 31/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.7063 - val_loss: 0.6554\n",
      "Epoch 32/100\n",
      "91142/91142 [==============================] - 3s 30us/step - loss: 0.6978 - val_loss: 0.6586\n",
      "Epoch 33/100\n",
      "91142/91142 [==============================] - 2s 27us/step - loss: 0.6979 - val_loss: 0.6557\n",
      "Epoch 34/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6975 - val_loss: 0.6657\n",
      "Epoch 35/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6982 - val_loss: 0.6565\n",
      "Epoch 36/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6954 - val_loss: 0.6591\n",
      "Epoch 37/100\n",
      "91142/91142 [==============================] - 3s 32us/step - loss: 0.6976 - val_loss: 0.6605\n",
      "Epoch 38/100\n",
      "91142/91142 [==============================] - 2s 27us/step - loss: 0.6955 - val_loss: 0.6505\n",
      "Epoch 39/100\n",
      "91142/91142 [==============================] - 2s 26us/step - loss: 0.6953 - val_loss: 0.6551\n",
      "Epoch 40/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6924 - val_loss: 0.6524\n",
      "Epoch 41/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6941 - val_loss: 0.6494\n",
      "Epoch 42/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6914 - val_loss: 0.6569\n",
      "Epoch 43/100\n",
      "91142/91142 [==============================] - 3s 28us/step - loss: 0.6910 - val_loss: 0.6601\n",
      "Epoch 44/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6879 - val_loss: 0.6501\n",
      "Epoch 45/100\n",
      "91142/91142 [==============================] - 3s 29us/step - loss: 0.6870 - val_loss: 0.6504\n",
      "Epoch 46/100\n",
      "91142/91142 [==============================] - 3s 28us/step - loss: 0.6860 - val_loss: 0.6472\n",
      "Epoch 47/100\n",
      "91142/91142 [==============================] - 2s 27us/step - loss: 0.6889 - val_loss: 0.6522\n",
      "Epoch 48/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6843 - val_loss: 0.6486\n",
      "Epoch 49/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6837 - val_loss: 0.6502\n",
      "Epoch 50/100\n",
      "91142/91142 [==============================] - 3s 28us/step - loss: 0.6810 - val_loss: 0.6563\n",
      "Epoch 51/100\n",
      "91142/91142 [==============================] - 3s 28us/step - loss: 0.6813 - val_loss: 0.6516\n",
      "Epoch 52/100\n",
      "91142/91142 [==============================] - 3s 34us/step - loss: 0.6795 - val_loss: 0.6491\n",
      "Epoch 53/100\n",
      "91142/91142 [==============================] - 3s 38us/step - loss: 0.6784 - val_loss: 0.6449\n",
      "Epoch 54/100\n",
      "91142/91142 [==============================] - 2s 26us/step - loss: 0.6782 - val_loss: 0.6454\n",
      "Epoch 55/100\n",
      "91142/91142 [==============================] - 4s 43us/step - loss: 0.6799 - val_loss: 0.6455\n",
      "Epoch 56/100\n",
      "91142/91142 [==============================] - 4s 49us/step - loss: 0.6798 - val_loss: 0.6464\n",
      "Epoch 57/100\n",
      "91142/91142 [==============================] - 3s 30us/step - loss: 0.6768 - val_loss: 0.6488\n",
      "Epoch 58/100\n",
      "91142/91142 [==============================] - 2s 26us/step - loss: 0.6771 - val_loss: 0.6513\n",
      "Epoch 59/100\n",
      "91142/91142 [==============================] - 2s 26us/step - loss: 0.6806 - val_loss: 0.6453- loss\n",
      "Epoch 60/100\n",
      "91142/91142 [==============================] - 2s 26us/step - loss: 0.6736 - val_loss: 0.6469\n",
      "Epoch 61/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6735 - val_loss: 0.6431\n",
      "Epoch 62/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6742 - val_loss: 0.6511\n",
      "Epoch 63/100\n",
      "91142/91142 [==============================] - 2s 27us/step - loss: 0.6731 - val_loss: 0.6481\n",
      "Epoch 64/100\n",
      "91142/91142 [==============================] - 3s 28us/step - loss: 0.6695 - val_loss: 0.6473\n",
      "Epoch 65/100\n",
      "91142/91142 [==============================] - 3s 32us/step - loss: 0.6728 - val_loss: 0.6460\n",
      "Epoch 66/100\n",
      "91142/91142 [==============================] - 2s 27us/step - loss: 0.6720 - val_loss: 0.6450\n",
      "Epoch 67/100\n",
      "91142/91142 [==============================] - 3s 28us/step - loss: 0.6677 - val_loss: 0.6476\n",
      "Epoch 68/100\n",
      "91142/91142 [==============================] - 3s 29us/step - loss: 0.6693 - val_loss: 0.6448\n",
      "Epoch 69/100\n",
      "91142/91142 [==============================] - 4s 42us/step - loss: 0.6692 - val_loss: 0.6505\n",
      "Epoch 70/100\n",
      "91142/91142 [==============================] - 3s 32us/step - loss: 0.6668 - val_loss: 0.6498\n",
      "Epoch 71/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6659 - val_loss: 0.6477\n",
      "Epoch 72/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6654 - val_loss: 0.6523\n",
      "Epoch 73/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6663 - val_loss: 0.6436\n",
      "Epoch 74/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6694 - val_loss: 0.6456\n",
      "Epoch 75/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6642 - val_loss: 0.6474\n",
      "Epoch 76/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6589 - val_loss: 0.6472\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6621 - val_loss: 0.6471\n",
      "Epoch 78/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6610 - val_loss: 0.6429\n",
      "Epoch 79/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6623 - val_loss: 0.6566\n",
      "Epoch 80/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6607 - val_loss: 0.6544\n",
      "Epoch 81/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6607 - val_loss: 0.6436\n",
      "Epoch 82/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6565 - val_loss: 0.6441\n",
      "Epoch 83/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6632 - val_loss: 0.6411\n",
      "Epoch 84/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6601 - val_loss: 0.6473\n",
      "Epoch 85/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6566 - val_loss: 0.6438\n",
      "Epoch 86/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6585 - val_loss: 0.6516\n",
      "Epoch 87/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6582 - val_loss: 0.6481\n",
      "Epoch 88/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6531 - val_loss: 0.6444\n",
      "Epoch 89/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6538 - val_loss: 0.6466\n",
      "Epoch 90/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6531 - val_loss: 0.6485\n",
      "Epoch 91/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6555 - val_loss: 0.6484\n",
      "Epoch 92/100\n",
      "91142/91142 [==============================] - 3s 30us/step - loss: 0.6515 - val_loss: 0.6501\n",
      "Epoch 93/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6516 - val_loss: 0.6464\n",
      "Epoch 94/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6480 - val_loss: 0.6476\n",
      "Epoch 95/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6545 - val_loss: 0.6457\n",
      "Epoch 96/100\n",
      "91142/91142 [==============================] - 2s 25us/step - loss: 0.6494 - val_loss: 0.6455\n",
      "Epoch 97/100\n",
      "91142/91142 [==============================] - 2s 24us/step - loss: 0.6505 - val_loss: 0.6500\n",
      "Epoch 98/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6560 - val_loss: 0.6416\n",
      "Epoch 99/100\n",
      "91142/91142 [==============================] - 2s 23us/step - loss: 0.6532 - val_loss: 0.6529\n",
      "Epoch 100/100\n",
      "91142/91142 [==============================] - 2s 27us/step - loss: 0.6476 - val_loss: 0.6454\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import TruncatedNormal\n",
    "\n",
    "sscaler = preprocessing.StandardScaler()\n",
    "x = pd.read_csv(\"resources/input.csv\", header=None)\n",
    "sscaler.fit(x)\n",
    "x = sscaler.transform(x)\n",
    "y = pd.read_csv(\"resources/answer.csv\", header=None)\n",
    "sscaler.fit(y)\n",
    "y = sscaler.transform(y)\n",
    "\n",
    "# トレーニング用とテスト用を分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "(x_train, x_test,\n",
    " y_train, y_test) = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=0,\n",
    ")\n",
    "\n",
    "# 隠れ層\n",
    "#n_hidden = 200\n",
    "n_hidden = 138\n",
    "# 出力層\n",
    "n_out = 1\n",
    "# 学習のエポック数\n",
    "epoch = 100\n",
    "# バッチサイズ\n",
    "batch_size = 100\n",
    "# モデルの作成\n",
    "model = Sequential()\n",
    "# 入力層 から 隠れ層\n",
    "model.add(Dense(n_hidden, input_shape=(x.shape[1],), kernel_initializer=TruncatedNormal(stddev=0.01)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "# 隠れ層の作成\n",
    "model.add((Dense(n_hidden,  kernel_initializer=TruncatedNormal(stddev=0.01))))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "# 隠れ層 から 出力層　恒等関数の使用\n",
    "model.add(Dense(n_out,  kernel_initializer=TruncatedNormal(stddev=0.01)))\n",
    "model.add(Activation('linear'))\n",
    "# 確率的勾配法　Adam\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# 損失関数　二乗和誤差\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer)\n",
    "# 学習の実施\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(x_test, y_test)\n",
    "                    )\n",
    "    \n",
    "model.save('model-v3.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
